{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lab 7: Compression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mehak Sharma  |  BioE 131  |  Fall 2019\n",
    "\n",
    "<b>Simulating the data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_gen(size, percentageZeros):\n",
    "    data = np.random.choice([0,1], size=size, replace=True, p=[percentageZeros, 1.0-percentageZeros])\n",
    "    data = np.packbits(data)\n",
    "    return data\n",
    "\n",
    "def DNA_gen(size):\n",
    "    data = np.random.choice(['A','T','C','G'], size=size, replace=True, p=[0.25 for _ in range(4)])\n",
    "    return data\n",
    "    \n",
    "def protein_gen(size):\n",
    "    data = np.random.choice(list('ARNDCEQGHILKMFPSTWYV'), size=size, replace=True, p=[0.05 for _ in range(20)])\n",
    "    return data\n",
    "    \n",
    "open('zeros_100p', 'wb').write(data_gen(8 * 10**6, 1.0))\n",
    "open('zeros_90p', 'wb').write(data_gen(8 * 10**6, 0.9))\n",
    "open('zeros_80p', 'wb').write(data_gen(8 * 10**6, 0.8))\n",
    "open('zeros_70p', 'wb').write(data_gen(8 * 10**6, 0.7))\n",
    "open('zeros_60p', 'wb').write(data_gen(8 * 10**6, 0.6))\n",
    "open('zeros_50p', 'wb').write(data_gen(8 * 10**6, 0.5))\n",
    "\n",
    "open('nt_seq.fa', 'w').write(''.join(DNA_gen(10**6))) \n",
    "open('aa_seq.fa', 'w').write(''.join(protein_gen(10**6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran commands similar to these on my terminal:\n",
    "- time gzip –c zeros_100p > zeros_100p.gz\n",
    "- time bzip2 –k zeros_100p \n",
    "- time pbzip2 –k zeros_100p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zeros_100p</th>\n",
       "      <th>zeros_90p</th>\n",
       "      <th>zeros_80p</th>\n",
       "      <th>zeros_70p</th>\n",
       "      <th>zeros_60p</th>\n",
       "      <th>zeros_50p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gzip</th>\n",
       "      <td>105MB, 102 kB, 0.717s</td>\n",
       "      <td>105MB, 58.7MB, 18.49s</td>\n",
       "      <td>105MB, 81.2MB, 13.407s</td>\n",
       "      <td>105MB, 93.6MB, 6.026s</td>\n",
       "      <td>105MB, 102MB, 4.373s</td>\n",
       "      <td>105MB, 102MB, 3.655s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bzip2</th>\n",
       "      <td>105MB, 113B, 1.020s</td>\n",
       "      <td>105MB, 61.7MB, 10.670s</td>\n",
       "      <td>105MB, 86.6MB, 11.941s</td>\n",
       "      <td>105MB, 99.8MB, 13.769s</td>\n",
       "      <td>105MB, 105MB, 15.721s</td>\n",
       "      <td>105MB, 105MB, 16.730s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pbzip2</th>\n",
       "      <td>105MB, 5.62KB, 0.104s</td>\n",
       "      <td>105MB, 61.2MB, 0.777s</td>\n",
       "      <td>105MB, 86.7MB, 0.981s</td>\n",
       "      <td>105MB, 99.8MB, 1.175s</td>\n",
       "      <td>105MB, 105MB, 1.433s</td>\n",
       "      <td>105MB, 105MB, 1.451s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   zeros_100p               zeros_90p               zeros_80p  \\\n",
       "gzip    105MB, 102 kB, 0.717s   105MB, 58.7MB, 18.49s  105MB, 81.2MB, 13.407s   \n",
       "bzip2     105MB, 113B, 1.020s  105MB, 61.7MB, 10.670s  105MB, 86.6MB, 11.941s   \n",
       "pbzip2  105MB, 5.62KB, 0.104s   105MB, 61.2MB, 0.777s   105MB, 86.7MB, 0.981s   \n",
       "\n",
       "                     zeros_70p              zeros_60p              zeros_50p  \n",
       "gzip     105MB, 93.6MB, 6.026s   105MB, 102MB, 4.373s   105MB, 102MB, 3.655s  \n",
       "bzip2   105MB, 99.8MB, 13.769s  105MB, 105MB, 15.721s  105MB, 105MB, 16.730s  \n",
       "pbzip2   105MB, 99.8MB, 1.175s   105MB, 105MB, 1.433s   105MB, 105MB, 1.451s  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'zeros_100p': [\"105MB, 102 kB, 0.717s\", \"105MB, 113B, 1.020s\", \"105MB, 5.62KB, 0.104s\"],\n",
    "     'zeros_90p' : [\"105MB, 58.7MB, 18.49s\", \"105MB, 61.7MB, 10.670s\", \"105MB, 61.2MB, 0.777s\"],\n",
    "     'zeros_80p' : [\"105MB, 81.2MB, 13.407s\", \"105MB, 86.6MB, 11.941s\", \"105MB, 86.7MB, 0.981s\"],\n",
    "     'zeros_70p' : [\"105MB, 93.6MB, 6.026s\", \"105MB, 99.8MB, 13.769s\", \"105MB, 99.8MB, 1.175s\"],\n",
    "     'zeros_60p' : [\"105MB, 102MB, 4.373s\", \"105MB, 105MB, 15.721s\", \"105MB, 105MB, 1.433s\"],\n",
    "     'zeros_50p' : [\"105MB, 102MB, 3.655s\", \"105MB, 105MB, 16.730s\", \"105MB, 105MB, 1.451s\"],\n",
    "    }\n",
    "dF = pd.DataFrame(data=d, index=['gzip', 'bzip2', 'pbzip2'])\n",
    "dF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq0</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gzip</th>\n",
       "      <td>100MB, 29.2MB, 12.140s</td>\n",
       "      <td>100MB, 29.2MB, 12.154s</td>\n",
       "      <td>100MB, 29.2MB, 12.142s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bzip2</th>\n",
       "      <td>100MB, 27.3MB, 9.487s</td>\n",
       "      <td>100MB, 27.3MB, 10.132s</td>\n",
       "      <td>100MB, 27.3MB, 9.650s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pbzip2</th>\n",
       "      <td>100MB, 27.3MB, 0.682s</td>\n",
       "      <td>100MB, 27.3MB, 0.671s</td>\n",
       "      <td>100MB, 27.3MB, 0.674s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seq0                    seq1                    seq2\n",
       "gzip    100MB, 29.2MB, 12.140s  100MB, 29.2MB, 12.154s  100MB, 29.2MB, 12.142s\n",
       "bzip2    100MB, 27.3MB, 9.487s  100MB, 27.3MB, 10.132s   100MB, 27.3MB, 9.650s\n",
       "pbzip2   100MB, 27.3MB, 0.682s   100MB, 27.3MB, 0.671s   100MB, 27.3MB, 0.674s"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {'seq0': [\"100MB, 29.2MB, 12.140s\", \"100MB, 27.3MB, 9.487s\", \"100MB, 27.3MB, 0.682s\"],\n",
    "     'seq1' : [\"100MB, 29.2MB, 12.154s\", \"100MB, 27.3MB, 10.132s\", \"100MB, 27.3MB, 0.671s\"],\n",
    "     'seq2' : [\"100MB, 29.2MB, 12.142s\", \"100MB, 27.3MB, 9.650s\", \"100MB, 27.3MB, 0.674s\"],\n",
    "    }\n",
    "dF2 = pd.DataFrame(data=d1, index=['gzip', 'bzip2', 'pbzip2'])\n",
    "dF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which algorithm achieves the best level of compression on each file type? <b>From zero percentage 100% to 50%, the best algorithms are bzip2, bzip2, bzip2, bzip2, gzip, gzip. For the DNA sequences, the best compression algorithm is tied between bzip2 and pbzip2.</b>\n",
    "\n",
    "- Which algorithm is the fastest? <b>bzip2 is the fastest algorithm.</b>\n",
    "\n",
    "- What is the difference between bzip2 and pbzip2? Do you expect one to be faster and why? <b>pbzip2 is significantly faster than bzip2. It appears that bzip2 is faster at compressing files with a higher percentage of zeroes. In general, pbzip is likely faster since it runs in parallel.</b>\n",
    "\n",
    "- How does the level of compression change as the percentage of zeros increases? Why does this happen? <b>The compression of the file appears to be inversely related to the percentage of zeroes, probably since there are fewer sections of uninterrupted entries of the same kind (zeros) that can be compressed.</b>\n",
    "\n",
    "- What is the minimum number of bits required to store a single DNA base? <b>0.25 bits because 25MB are sufficient to encode 100MB of DNA data.</b>\n",
    "\n",
    "- What is the minimum number of bits required to store an amino acid letter? <b>4.322 </b>\n",
    "\n",
    "- In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and protein sequences? <b>gzip and bzip2 took 29.2 and 27.3 MB respectively.</b>\n",
    "\n",
    "- Are gzip and bzip2 performing well on DNA and proteins? <b>gzip and bzip2 are both only a few MB off from the ideal 25MB.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compressing real data</b>\n",
    "\n",
    "Now that you have a sense of how random data can be compressed, let’s have a look at some real biological data. Using what you’ve learned about querying biological databases, find the nucleic acid sequences of gp120 homologs from at least 10 different HIV isolates and concatenate them together into a single multi-FASTA. \n",
    "\n",
    "- <b> A priori, do you expect to achieve better or worse compression here than random data? Why? </b>\n",
    "I would expect the compression here to work worse since there are often more randomized sequences than repeated ones in real DNA sequences.\n",
    " \n",
    "Now, compress the multi-FASTA using gzip and bzip2. \n",
    "\n",
    "% Compression:\n",
    "- gzip - random: 70.7, gp120: 75.4\n",
    "- bzip2 - random: 72.6, gp120: 78.2\n",
    "- pbzip2 - random: 72.6, gp120: 78.2\n",
    "\n",
    "\n",
    "- <b>How does the compression ratio of this file compare to random data? </b>\n",
    "It appears that the compression ratios for gzip, bzip, and pbzip are better in gp120 homologs FASTA file in comparison to the randomized data we generated in part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Estimating compression of 1000 terabytes</b>\n",
    "\n",
    "Given the benchmarking data you obtained in this lab..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Which algorithm do you propose to use for each type of data?</b>\n",
    "\n",
    "For re-sequencing of similar genomes, I propose using pbzip2 for parallel compression.\n",
    "\n",
    "For protein sequences, I propose using pbzip2 since it would also work fastest among the algorithms, while simultanesouly providing approximately the same compression as gzip2.\n",
    "\n",
    "For random binary microscope images, it appears that gzip2 provides the best compression.\n",
    "\n",
    "Provide an estimate for the fraction of space you can save using your compression scheme.\n",
    "\n",
    "- for 800TB (of genomes and plasmids): 78.2% compressed\n",
    "- for 100TB (of protein sequences): 71.2% compressed\n",
    "- for 100TB (of a binary image): 0% compressed\n",
    "- in total, 174.4 + 28.8 + 0 = 203.2 TB / 1000TB (79.68% compressed)\n",
    "\n",
    "<b>How much of a bonus do you anticipate receiving this year?</b>\n",
    "- Bonus = 50 dollars/TB of hard disk space saved\n",
    "- 50 dollars x 796.8 TB saved = 39,840 dollars/day\n",
    "- Annual bonus = 39,840 dollars/day * 365 days/year = 14,541,600 dollars for the entire year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
